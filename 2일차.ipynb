{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) 머신러닝 - 회귀 \n",
    "- 회귀 분석 : 데이터를 가장 잘 설명하는 모델을 찾아 입력 값에 따른 미래 결과 값을 예측하는 알고리즘\n",
    "- 완벽한 예측은 불가능하기에 최대한 잘 근사해야 한다.\n",
    "- 예측 값과 실제 값의 차이를 최소한으로 하는 선을 찾아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 단순 선형 회귀\n",
    "- 데이터를 설명하는 모델을 직선형태로 가정\n",
    "- 가정 : Y = B0 + B1X  = 직선을 구성하는 B0 (y절편)와 B1(기울기)를 구해야 함\n",
    "- 특징\n",
    "    1. 가장 기초적이나 여전히 많이 사용되는 알고리즘\n",
    "    2. 입력 값이 1개인 경우에만 적용이 가능함\n",
    "    3. 입력 값과 결과 값의 관계를 알아보는데 용이함\n",
    "    4. 입력 값이 결과 값에 얼마나 영향을 미치는지 알 수 있음\n",
    "    5. 두 변수 간의 관계를 직관적으로 해석하고자 하는 경우 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss 함수\n",
    "- 실제 값과 예측 값 차이의 제곱의 합을 Loss 함수로 정의 -> Loss함수가 작을 수록 좋은 모델.\n",
    "- Loss 함수를 크기를 작게 하는 B0(y절편), B1(기울기)를 찾는 방법\n",
    "    1. Grandient descent ( 경사 하강법 )\n",
    "          - 가장 보편적이고 딥러닝에서 많이 사용됨\n",
    "          - 방식 : 랜덤 초기화 -> Loss 값 계산 -> Gradient 계산 -> B0, B1 값 업데이트\n",
    "    2. Normal equation ( least squares )\n",
    "    3. Brute force search\n",
    "    4. ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단순 선형 회귀 예시\n",
    "- lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.\n",
    "- lrmodel.fit(train_X, train_Y) # train_X와 train_Y를 이용하여 모델을 학습 시킵니다.\n",
    "- pred_X = lrmodel.predict(train_X) # predict() 를 이용하여 예측합니다.\n",
    "- print('train_X에 대한 예측값 : \\n{}\\n'.format(pred_X))\n",
    "- print('실제값 : \\n{}'.format(train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 다중선형 회귀\n",
    "- 여러 개의 입력 값을 활용할 수 있는 회귀 알고리즘, 각 개별 Xi 에 해당하는 최적의 Bi를 찾아야 함\n",
    "- ex) 평균 기온(X1)과 평균 강수량(X2)에 따른 아이스크림 판매량을 예측하고자 함\n",
    "- 특징\n",
    "   1. 여러 개의 입력 값과 결과 값 간의 관계 확인 가능\n",
    "   2. 어떤 입력 값이 결과 값에 어떠한 영향을 미치는지 알 수 있음\n",
    "   3. 여러 개의 입력 값 사이 간의 상관 관계가 높을 경우 결과에 대한 신뢰성을 잃을 가능성이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss 함수 \n",
    "- 단순 선형 회귀와 마찬가지로 입력 값과 실제 값의 차이의 제곱의 합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 다중 선형 회귀 예시\n",
    "- X = df.drop(columns=['Sales'])\n",
    "- Y = df['Sales']\n",
    "- train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "- lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.\n",
    "- lrmodel.fit(train_X, train_Y) # train_X와 train_Y 데이터로 모델을 학습합니다.\n",
    "- beta_0 = lrmodel.intercept_ # y절편 (기본 판매량)\n",
    "- beta_1 = lrmodel.coef_[0] # 1번째 변수에 대한 계수 (페이스북)\n",
    "- beta_2 = lrmodel.coef_[1] # 2번째 변수에 대한 계수 (TV)\n",
    "- beta_3 = lrmodel.coef_[2] # 3번째 변수에 대한 계수 (신문)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 회귀 알고리즘 평가\n",
    "- 목표를 얼마나 잘 달성했는지 정도를 평가해야 함\n",
    "1. RSS - 단순 오차\n",
    "    - 실제 값과 예측 값의 단순 초차 제곱 합\n",
    "    - 값이 작을 수록 모델의 성능이 높음\n",
    "    - 전체 데이터에 대한 실제 값과 예측하는 값의 오차 제곱의 총 합\n",
    "    - 특징 \n",
    "        - 가장 간단한 평가 방법으로 직관적인 해석 가능\n",
    "        - 오차를 그대로 이용하기 때문에 입력 값의 크기에 의존적\n",
    "        - 절대적인 값과 비교가 불가능함\n",
    "2. MSE - 평균 제곱 오차\n",
    "    - RSS에서 데이터 수 만큼 나눈 값 작을수록 모델의 성능이 높다고 평가\n",
    "    - 이상치, 데이터들 중 크게 떨어진 값에 민감함\n",
    "3. MAE - 평균 절대값 오차\n",
    "    - 실제 값과 예측 값의 오차의 절대 값의 평균 작을수록 모델의 성능이 높다고 평가\n",
    "    - 변동성이 큰 지표와 낮은 지표를 같이 예측할 시 유용\n",
    "    - MSE, MAE 공통 특징\n",
    "        - 가장 간단한 평가 방법들로 직관적인 해석 가능\n",
    "        - 평균을 그대로 이용하기 때문에 입력 값의 크기에 의존적\n",
    "        - 절대적인 값과 비교가 불가능\n",
    "4. R2 - 결정계수\n",
    "    - 회귀 모델의 설명력을 표현하는 지표 \n",
    "    - 1에 가까울 수록 높은 성능의 모델\n",
    "    - 특징\n",
    "       - 오차에 없을수록 1에 가까운 값을 갖음\n",
    "       - 값이 0인 경우, 데이터의 평균 값을 출력하는 직선 모델을 의미함\n",
    "       - 음수 값이 나온 경우, 평균 값 예측보다 성능이 좋지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 평가 알고리즘의 예시\n",
    "- RSS : RSS_test = np.sum( (test_Y - pred_test) ** 2) # 예측값과 실제값의 오차제곱합을 구합니다.\n",
    "- MSE : MSE_train = mean_squared_error(train_Y, pred_train) # mean_squared_error() 를 활용해서 MSE를 계산합니다.\n",
    "- MAE : MAE_train = mean_absolute_error(train_Y, pred_train) # mean_absolute_error() 를 활용해서 MAE를 계산합니다.\n",
    "- R2 : R2_train = r2_score(train_Y, pred_train) # r2_score()를 활용하여 R2값을 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold 교차 검증 - 평가 신뢰도 높이기\n",
    "- 학습용 데이터에 과적합되는 경우를 막기 위해서 테스트 데이터 이용\n",
    "##### K-fold 예시\n",
    "- KFold(n_splits=5) # K=5 인 K-fold instance 생성\n",
    "- n_try = 1\n",
    "- MSE_arr = []\n",
    "  - for train_index, test_index in kf.split(X):\n",
    "       - train_X, test_X = X.loc[train_index], X.loc[test_index]\n",
    "       - train_Y, test_Y = Y.loc[train_index], Y.loc[test_index]\n",
    "       - lrmodel = LinearRegression()\n",
    "       - lrmodel.fit(train_X, train_Y)\n",
    "       - pred_test = lrmodel.predict(test_X)\n",
    "       - MSE_test = mean_squared_error(test_Y, pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 다양한 선형 회귀 모델 ( scikit-learn 패키지)\n",
    "1. Least Square 모델\n",
    "   - 잔차(RSS)를 최소화하는 weight를 찾음\n",
    "2. Ridge 선형 회귀 모델\n",
    "   - 과적합되기 쉬운 least square 모델을 보완하기 위한 모델\n",
    "   - 잔차에 weight 제곱합을 더한 값을 최소화하도록 학습\n",
    "3. Lasso 선형 회귀 모델\n",
    "   - 과적합 방지하고자 고안된 모델\n",
    "   - 잔차에 weight 절대값의 합을 더한 값을 최소화하도록 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90e68e2d215918e27054de83af9e76c00ba81faef2a1fcd4e4ecb816270b0b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
